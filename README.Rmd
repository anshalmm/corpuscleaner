---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  message = F,
  warning = F
)
```

# corpuscleaner

<!-- badges: start -->
<!-- badges: end -->

## Overview 
The `{corpuscleaner}` package has a collection of `18 Documents` cleaned and ready for use regarding Corpus Analysis. It has a `novels()` function which has the collection consisting of: 

* `ID`: ID of the Document
* `title`: Title of the Document
* `text`: Text of the Document 
* `year`: Year the Document was Published 
* `author`: Author of the Document

It also has a function `novels_by_ID(ID, vars)` that has a `tibble` consisting of the Document's: 

* `ID`
* `text` 

and can add any `column_names` of your choice such as the `year`, `author`, or both. 

## Installation

You can install the development version of corpuscleaner from [GitHub](https://github.com/) with:

``` r
# install.packages("corpuscleaner")
devtools::install_github("anshalmm/corpuscleaner")
```

## Examples

These are basic examples of what `corpuscleaner` can do when combined with basic text analysis:

```{r example}
library(corpuscleaner)
library(dplyr)
library(tidytext)
```

Here we're using the `novels()` function and filtering it out to find the metadata of the document `Wuthering Heights`


```{r}
WH_Text = novels() %>%
  filter(title == "Wuthering Heights")

WH_Text
```


Here, we can use the `novels_by_ID` function to extract the ID, text, and an additional column, author, for the document `Vathek`.

Additionally, we can do some frequency list text analysis on this document by finding all the unigrams in it:


```{r}
novels()
novels_by_ID(ID = 2, vars = "year")
unigram_Analysis = novels_by_ID(ID = 2, vars = "year")

UA = unigram_Analysis %>%
  unnest_tokens(word, 
                text, 
                token = "words") %>%
  anti_join(get_stopwords("en", source = "smart")) 

UA_Count_Words = UA %>%
  count(word, sort = T)
UA_Count_Words
```


If you would like to know more about this package, please see the [Get started](https://anshalmm.github.io/corpuscleaner/articles/corpuscleaner.html) Page.  
