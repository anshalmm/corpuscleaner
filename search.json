[{"path":"https://anshalmm.github.io/corpuscleaner/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 corpuscleaner authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/articles/corpuscleaner.html","id":"understanding-corpuscleaner","dir":"Articles","previous_headings":"","what":"Understanding corpuscleaner","title":"Introduction of corpuscleaner","text":"corpuscleaner package two datasets called Documents novels_tgt, one row per line format text. consists five variables : ID: ID Document title: Title Document text: Text Document year: Year Document Published author: Author Document also includes two functions: novels() 18 Document collection one row per line text along variables . document_by_ID minimizes using two datasets text analysis, instead pick, id, document choice additional column name, year document published.","code":"novels() %>%   unnest_tokens(word,                  text,                  token = \"words\") %>%   anti_join(get_stopwords(\"en\", source = \"smart\")) %>%   count(ID, title, word, sort = T) #> # A tibble: 143,198 × 4 #>       ID title                    word         n #>    <dbl> <chr>                    <chr>    <int> #>  1     7 The Mysteries of Udolpho emily     2227 #>  2    16 The Portrait of a Lady   isabel    1485 #>  3    13 North and South          margaret  1443 #>  4    13 North and South          mr         989 #>  5    10 Ivanhoe                  thou       947 #>  6     7 The Mysteries of Udolpho montoni    918 #>  7    14 The Woman in White       sir        842 #>  8    16 The Portrait of a Lady   don        833 #>  9    14 The Woman in White       percival   749 #> 10    15 Great Expectations       joe        747 #> # ℹ 143,188 more rows  Documents #> # A tibble: 18 × 5 #>    id    title                          text                        year  author #>    <chr> <chr>                          <chr>                       <chr> <chr>  #>  1 1     Vathek                         vathek an arabian tale by … 1786  Beckf… #>  2 2     A Sicilian Romance             a sicilian romance by ann … 1790  Radcl… #>  3 3     The Mysteries of Udulpho       the mysteries of udolpho a… 1794  Radcl… #>  4 4     The Monk: A Romance            the monk a romance by matt… 1795  Lewis… #>  5 5     Sense and Sensibility          sense and sensibility by j… 1811  Auste… #>  6 6     Frankenstein                   frankenstein or the modern… 1818  Shell… #>  7 7     Ivanhoe                        ivanhoe a romance by sir w… 1820  Scott… #>  8 8     Narrative of Arthur Gordon Pym narrative of a gordon pym … 1838  Poe, … #>  9 9     Wuthering Heights              wuthering heights chapter … 1847  Bront… #> 10 10    The House of Seven Gables      the house of the seven gab… 1851  Hawth… #> 11 11    North and South                north and south by elizabe… 1854  Gaske… #> 12 12    The Woman in White             the woman in white by wilk… 1860  Colli… #> 13 13    Great Expectations             chapter i my father s fami… 1861  Dicke… #> 14 14    The Portrait of a Lady         chapter i under certain ci… 1881  James… #> 15 15    Treasure Island                to the hesitating purchase… 1882  Steve… #> 16 16    Dr Jekyll and Hyde             strange case of dr jekyll … 1886  Steve… #> 17 17    The Picture of Dorian Gray     the artist is the creator … 1890  Wilde… #> 18 18    Dracula                        chapter jonathan harker s … 1897  Stoke… document_by_ID(id == 1, vars = \"year\") #> # A tibble: 1 × 3 #> # Groups:   id, text [1] #>   id    text                                                               year  #>   <chr> <chr>                                                              <chr> #> 1 1     vathek an arabian tale by william beckford esq p vathek vathek ni… 1786"},{"path":"https://anshalmm.github.io/corpuscleaner/articles/corpuscleaner.html","id":"usage-in-text-analysis","dir":"Articles","previous_headings":"","what":"Usage in Text Analysis","title":"Introduction of corpuscleaner","text":"Aside , can higher text analysis using novels tf-idf: Topic Modeling: Therefore, package useful higher basic Text Analysis.","code":"# Part 1: Finding the commonly used words in all documents doc_words = novels() %>%   unnest_tokens(word, text) %>%   count(title, word, sort = T)  tot_words = doc_words %>%   group_by(title) %>%    summarize(total = sum(n))  put_words = left_join(doc_words, tot_words) put_words #> # A tibble: 150,525 × 4 #>    title                    word      n  total #>    <chr>                    <chr> <int>  <int> #>  1 The Mysteries of Udolpho the   19063 294093 #>  2 The Woman in White       the   14947 250487 #>  3 Ivanhoe                  the   12464 179284 #>  4 The Mysteries of Udolpho and    9818 294093 #>  5 The Mysteries of Udolpho to     9693 294093 #>  6 The Mysteries of Udolpho of     9523 294093 #>  7 The Woman in White       to     8486 250487 #>  8 Great Expectations       the    8145 188943 #>  9 The Portrait of a Lady   the    8066 233165 #> 10 Dracula                  the    7865 161799 #> # ℹ 150,515 more rows  # Part 2: Using Zipf's law in Finding Word Frequency frequency_rank = put_words %>%   group_by(title) %>%   mutate(rank = row_number(),          term_frequency = n/total) %>%   ungroup()  frequency_rank #> # A tibble: 150,525 × 6 #>    title                    word      n  total  rank term_frequency #>    <chr>                    <chr> <int>  <int> <int>          <dbl> #>  1 The Mysteries of Udolpho the   19063 294093     1         0.0648 #>  2 The Woman in White       the   14947 250487     1         0.0597 #>  3 Ivanhoe                  the   12464 179284     1         0.0695 #>  4 The Mysteries of Udolpho and    9818 294093     2         0.0334 #>  5 The Mysteries of Udolpho to     9693 294093     3         0.0330 #>  6 The Mysteries of Udolpho of     9523 294093     4         0.0324 #>  7 The Woman in White       to     8486 250487     2         0.0339 #>  8 Great Expectations       the    8145 188943     1         0.0431 #>  9 The Portrait of a Lady   the    8066 233165     1         0.0346 #> 10 Dracula                  the    7865 161799     1         0.0486 #> # ℹ 150,515 more rows # Using novels to do some Topic Modeling # Part 1: Find the books you want to use in Topic Modeling  # Search for Novels that have CHAPTER I... In Them  novels() %>%   filter(str_detect(text, \"^chapter \")) %>%   select(title, text) #> # A tibble: 352 × 2 #>    title             text         #>    <chr>             <chr>        #>  1 Wuthering Heights chapter i    #>  2 Wuthering Heights chapter ii   #>  3 Wuthering Heights chapter iii  #>  4 Wuthering Heights chapter iv   #>  5 Wuthering Heights chapter v    #>  6 Wuthering Heights chapter vi   #>  7 Wuthering Heights chapter vii  #>  8 Wuthering Heights chapter viii #>  9 Wuthering Heights chapter ix   #> 10 Wuthering Heights chapter x    #> # ℹ 342 more rows  # Optional:  # novels() %>% #   filter(str_detect(text, \"^chapter \")) %>% #   select(title, text) %>% #   print(n = 250)  book_titles = c(\"Frankenstein\", \"Ivanhoe\", \"The Portrait of a Lady\", \"Wuthering Heights\")  books = novels() %>%   filter(title %in% book_titles)  # Diving these books by chapter  book_chapters = books %>%   group_by(title) %>%   mutate(chapter = cumsum(str_detect(text, \"^chapter \"))) %>%   filter(chapter > 0) %>%   unite(document, title, chapter)  book_words = book_chapters %>%   unnest_tokens(word, text)   book_wordcounts = book_words %>%   anti_join(get_stopwords(\"en\", source = \"smart\")) %>%   count(document, word, sort = T)  book_wordcounts #> # A tibble: 140,505 × 3 #>    document                  word       n #>    <chr>                     <chr>  <int> #>  1 Ivanhoe_27                thou      75 #>  2 The Portrait of a Lady_19 isabel    69 #>  3 Ivanhoe_40                knight    66 #>  4 Ivanhoe_27                de        61 #>  5 The Portrait of a Lady_40 isabel    61 #>  6 Ivanhoe_39                thou      60 #>  7 The Portrait of a Lady_51 isabel    57 #>  8 Ivanhoe_33                thou      55 #>  9 Ivanhoe_33                prior     53 #> 10 The Portrait of a Lady_52 isabel    53 #> # ℹ 140,495 more rows  # Part 2: Convert to LDA for Topic Modeling book_chapter_DTM = book_wordcounts %>%   cast_dtm(document, word, n)  book_chapter_DTM #> <<DocumentTermMatrix (documents: 157, terms: 19685)>> #> Non-/sparse entries: 140505/2950040 #> Sparsity           : 95% #> Maximal term length: 18 #> Weighting          : term frequency (tf)  # Use LDA in Four Topic Modeling given we have Four Documents book_chapter_LDA = LDA(book_chapter_DTM, k = 4, control = list(seed = 1234)) book_chapter_LDA #> A LDA_VEM topic model with 4 topics.  # Finally, examine a per topic per word probabilities  book_topics = tidy(book_chapter_LDA, matrix = \"beta\") book_topics #> # A tibble: 78,740 × 3 #>    topic term        beta #>    <int> <chr>      <dbl> #>  1     1 thou   2.16e-  4 #>  2     2 thou   3.70e-  4 #>  3     3 thou   6.10e-172 #>  4     4 thou   1.26e-  2 #>  5     1 isabel 2.07e- 11 #>  6     2 isabel 5.23e- 21 #>  7     3 isabel 1.93e-  2 #>  8     4 isabel 9.50e-208 #>  9     1 knight 3.88e- 22 #> 10     2 knight 4.70e- 36 #> # ℹ 78,730 more rows"},{"path":"https://anshalmm.github.io/corpuscleaner/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Anshal Majmudar. Author, maintainer.","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Majmudar (2024). corpuscleaner: Tibble 18 Cleaned Documents usable Text Analysis. R package version 0.1.0, https://anshalmm.github.io/corpuscleaner/.","code":"@Manual{,   title = {corpuscleaner: A Tibble of 18 Cleaned Documents usable for Text Analysis},   author = {Anshal Majmudar},   year = {2024},   note = {R package version 0.1.0},   url = {https://anshalmm.github.io/corpuscleaner/}, }"},{"path":[]},{"path":"https://anshalmm.github.io/corpuscleaner/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"A Tibble of 18 Cleaned Documents usable for Text Analysis","text":"corpuscleaner package collection 18 Documents cleaned ready use regarding Text Analysis. dataset Documents collection consisting : ID: ID Document title: Title Document text: Text Document year: Year Document Published author: Author Document Along , package function novels one row per line format text, along variables listed . also function document_by_ID(..., vars) tibble consisting Document’s: id text can add column_names choice year, author, .","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A Tibble of 18 Cleaned Documents usable for Text Analysis","text":"can install development version corpuscleaner GitHub :","code":"# install.packages(\"corpuscleaner\") devtools::install_github(\"anshalmm/corpuscleaner\")"},{"path":"https://anshalmm.github.io/corpuscleaner/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"A Tibble of 18 Cleaned Documents usable for Text Analysis","text":"basic examples corpuscleaner can combined basic text analysis: , can use document_by_ID function extract id, text, additional column, author, document Vathek. Additionally, can frequency list text analysis document finding unigrams : like know package, please see Get started Page.","code":"library(corpuscleaner) library(dplyr) library(tidytext)  novels() %>%   unnest_tokens(word,                  text,                  token = \"words\") %>%   anti_join(get_stopwords(\"en\", source = \"smart\")) #> # A tibble: 895,673 × 5 #>       ID title              year author        word      #>    <dbl> <chr>             <dbl> <chr>         <chr>     #>  1     1 Wuthering Heights  1847 Bronte, Emily wuthering #>  2     1 Wuthering Heights  1847 Bronte, Emily heights   #>  3     1 Wuthering Heights  1847 Bronte, Emily chapter   #>  4     1 Wuthering Heights  1847 Bronte, Emily returned  #>  5     1 Wuthering Heights  1847 Bronte, Emily visit     #>  6     1 Wuthering Heights  1847 Bronte, Emily landlord  #>  7     1 Wuthering Heights  1847 Bronte, Emily solitary  #>  8     1 Wuthering Heights  1847 Bronte, Emily neighbour #>  9     1 Wuthering Heights  1847 Bronte, Emily troubled  #> 10     1 Wuthering Heights  1847 Bronte, Emily beautiful #> # ℹ 895,663 more rows Documents #> # A tibble: 18 × 5 #>    id    title                          text                        year  author #>    <chr> <chr>                          <chr>                       <chr> <chr>  #>  1 1     Vathek                         vathek an arabian tale by … 1786  Beckf… #>  2 2     A Sicilian Romance             a sicilian romance by ann … 1790  Radcl… #>  3 3     The Mysteries of Udulpho       the mysteries of udolpho a… 1794  Radcl… #>  4 4     The Monk: A Romance            the monk a romance by matt… 1795  Lewis… #>  5 5     Sense and Sensibility          sense and sensibility by j… 1811  Auste… #>  6 6     Frankenstein                   frankenstein or the modern… 1818  Shell… #>  7 7     Ivanhoe                        ivanhoe a romance by sir w… 1820  Scott… #>  8 8     Narrative of Arthur Gordon Pym narrative of a gordon pym … 1838  Poe, … #>  9 9     Wuthering Heights              wuthering heights chapter … 1847  Bront… #> 10 10    The House of Seven Gables      the house of the seven gab… 1851  Hawth… #> 11 11    North and South                north and south by elizabe… 1854  Gaske… #> 12 12    The Woman in White             the woman in white by wilk… 1860  Colli… #> 13 13    Great Expectations             chapter i my father s fami… 1861  Dicke… #> 14 14    The Portrait of a Lady         chapter i under certain ci… 1881  James… #> 15 15    Treasure Island                to the hesitating purchase… 1882  Steve… #> 16 16    Dr Jekyll and Hyde             strange case of dr jekyll … 1886  Steve… #> 17 17    The Picture of Dorian Gray     the artist is the creator … 1890  Wilde… #> 18 18    Dracula                        chapter jonathan harker s … 1897  Stoke… document_by_ID(id == 1, vars = \"year\") #> # A tibble: 1 × 3 #> # Groups:   id, text [1] #>   id    text                                                               year  #>   <chr> <chr>                                                              <chr> #> 1 1     vathek an arabian tale by william beckford esq p vathek vathek ni… 1786 unigram_Analysis = document_by_ID(id == 1, vars = \"year\")  UA = unigram_Analysis %>%   unnest_tokens(word,                  text,                  token = \"words\") %>%   anti_join(get_stopwords(\"en\", source = \"smart\"))   UA_Count_Words = UA %>%   count(word, sort = T) UA_Count_Words #> # A tibble: 5,396 × 3 #> # Groups:   id [1] #>    id    word            n #>    <chr> <chr>       <int> #>  1 1     caliph        151 #>  2 1     vathek        125 #>  3 1     nouronihar     87 #>  4 1     carathis       79 #>  5 1     thy            78 #>  6 1     thou           72 #>  7 1     whilst         66 #>  8 1     bababalouk     55 #>  9 1     gulchenrouz    54 #> 10 1     palace         47 #> # ℹ 5,386 more rows"},{"path":"https://anshalmm.github.io/corpuscleaner/reference/Documents.html","id":null,"dir":"Reference","previous_headings":"","what":"Dataset of 18 Cleaned Documents — Documents","title":"Dataset of 18 Cleaned Documents — Documents","text":"Tibble 18 Cleaned Documents usable Corpus Analysis","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/reference/Documents.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dataset of 18 Cleaned Documents — Documents","text":"","code":"Documents"},{"path":"https://anshalmm.github.io/corpuscleaner/reference/Documents.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dataset of 18 Cleaned Documents — Documents","text":"tibble 369111 rows 5 variables consisting : id ID Documents title Title Documents text Text Documents year Year Published authors Authors Documents","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/reference/corpuscleaner-package.html","id":null,"dir":"Reference","previous_headings":"","what":"corpuscleaner: A Tibble of 18 Cleaned Documents usable for Text Analysis — corpuscleaner-package","title":"corpuscleaner: A Tibble of 18 Cleaned Documents usable for Text Analysis — corpuscleaner-package","text":"package two major functions novels() polish(..., vars). know please refer Vignette.","code":""},{"path":[]},{"path":"https://anshalmm.github.io/corpuscleaner/reference/corpuscleaner-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"corpuscleaner: A Tibble of 18 Cleaned Documents usable for Text Analysis — corpuscleaner-package","text":"Maintainer: Anshal Majmudar ammajmudar@ucdavis.edu","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/reference/document_by_ID.html","id":null,"dir":"Reference","previous_headings":"","what":"Documents Extraction — document_by_ID","title":"Documents Extraction — document_by_ID","text":"function allows extract document choice based title choose along extra parameters like see `year` `author`.","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/reference/document_by_ID.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Documents Extraction — document_by_ID","text":"","code":"document_by_ID(..., vars)"},{"path":"https://anshalmm.github.io/corpuscleaner/reference/document_by_ID.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Documents Extraction — document_by_ID","text":"... Input ID (.e., 1:18) `Documents` dataset vars Input column variable `Documents` dataset","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/reference/document_by_ID.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Documents Extraction — document_by_ID","text":"tibble `id`, `text`, column variable choice","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/reference/document_by_ID.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Documents Extraction — document_by_ID","text":"","code":"document_by_ID(id == 11, vars = c(\"year\", \"author\")) #> # A tibble: 1 × 4 #> # Groups:   id, text [1] #>   id    text                                                        year  author #>   <chr> <chr>                                                       <chr> <chr>  #> 1 11    north and south by elizabeth gaskell wooed and married and… 1854  Gaske…"},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels.html","id":null,"dir":"Reference","previous_headings":"","what":"18 Cleaned Novels — novels","title":"18 Cleaned Novels — novels","text":"complete cleaned tibble 18 Novels usable Corpus Analytics","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"18 Cleaned Novels — novels","text":"","code":"novels()"},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"18 Cleaned Novels — novels","text":"dataframe 369111 rows 5 variables","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"18 Cleaned Novels — novels","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union library(tidytext) novels() %>%   unnest_tokens(word, text) %>%   anti_join(get_stopwords(\"en\", source = \"smart\")) %>%   count(ID, title, word, sort = T) #> Joining with `by = join_by(word)` #> # A tibble: 143,198 × 4 #>       ID title                    word         n #>    <dbl> <chr>                    <chr>    <int> #>  1     7 The Mysteries of Udolpho emily     2227 #>  2    16 The Portrait of a Lady   isabel    1485 #>  3    13 North and South          margaret  1443 #>  4    13 North and South          mr         989 #>  5    10 Ivanhoe                  thou       947 #>  6     7 The Mysteries of Udolpho montoni    918 #>  7    14 The Woman in White       sir        842 #>  8    16 The Portrait of a Lady   don        833 #>  9    14 The Woman in White       percival   749 #> 10    15 Great Expectations       joe        747 #> # ℹ 143,188 more rows"},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels_tgt.html","id":null,"dir":"Reference","previous_headings":"","what":"A Tibble of 18 Cleaned Documents usable for Corpus Analysis with one row per line of text. — novels_tgt","title":"A Tibble of 18 Cleaned Documents usable for Corpus Analysis with one row per line of text. — novels_tgt","text":"Tibble 18 Cleaned Documents usable Corpus Analysis one row per line text.","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels_tgt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A Tibble of 18 Cleaned Documents usable for Corpus Analysis with one row per line of text. — novels_tgt","text":"","code":"novels_tgt"},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels_tgt.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A Tibble of 18 Cleaned Documents usable for Corpus Analysis with one row per line of text. — novels_tgt","text":"tibble 369111 rows 5 variables consisting : ID ID Documents title Title Documents text Text Documents year Year Published authors Authors Documents","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/news/index.html","id":"corpuscleaner-010","dir":"Changelog","previous_headings":"","what":"corpuscleaner 0.1.0","title":"corpuscleaner 0.1.0","text":"Initial CRAN submission.","code":""}]
