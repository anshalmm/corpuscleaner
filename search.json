[{"path":"https://anshalmm.github.io/corpuscleaner/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 corpuscleaner authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/articles/corpuscleaner.html","id":"understanding-corpuscleaner","dir":"Articles","previous_headings":"","what":"Understanding corpuscleaner","title":"Introduction of corpuscleaner","text":"corpuscleaner package tibble called novels() consists 18 cleaned documents usable basic text analysis. also includes function called novels_by_ID minimizes using entire novels() tibble text analysis, instead pick, ID, document choice column names, year novel published, author novel, .","code":"novels() %>%   unnest_tokens(word,                  text,                  token = \"words\") %>%   anti_join(get_stopwords(\"en\", source = \"smart\")) #> # A tibble: 895,673 × 5 #>       ID title              year author        word      #>    <dbl> <chr>             <dbl> <chr>         <chr>     #>  1     1 Wuthering Heights  1847 Bronte, Emily wuthering #>  2     1 Wuthering Heights  1847 Bronte, Emily heights   #>  3     1 Wuthering Heights  1847 Bronte, Emily chapter   #>  4     1 Wuthering Heights  1847 Bronte, Emily returned  #>  5     1 Wuthering Heights  1847 Bronte, Emily visit     #>  6     1 Wuthering Heights  1847 Bronte, Emily landlord  #>  7     1 Wuthering Heights  1847 Bronte, Emily solitary  #>  8     1 Wuthering Heights  1847 Bronte, Emily neighbour #>  9     1 Wuthering Heights  1847 Bronte, Emily troubled  #> 10     1 Wuthering Heights  1847 Bronte, Emily beautiful #> # ℹ 895,663 more rows novels() #> # A tibble: 369,611 × 5 #>       ID title             text                                      year author #>    <dbl> <chr>             <chr>                                    <dbl> <chr>  #>  1     1 Wuthering Heights WUTHERING HEIGHTS                         1847 Bront… #>  2     1 Wuthering Heights CHAPTER I                                 1847 Bront… #>  3     1 Wuthering Heights I have just returned from a visit to my…  1847 Bront… #>  4     1 Wuthering Heights This is certainly a beautiful country     1847 Bront… #>  5     1 Wuthering Heights In all England                            1847 Bront… #>  6     1 Wuthering Heights I do not believe that I could have fixe…  1847 Bront… #>  7     1 Wuthering Heights A perfect misanthropist s heaven          1847 Bront… #>  8     1 Wuthering Heights and Mr                                    1847 Bront… #>  9     1 Wuthering Heights Heathcliff and I are such a suitable pa…  1847 Bront… #> 10     1 Wuthering Heights A capital fellow                          1847 Bront… #> # ℹ 369,601 more rows novels_by_ID(ID = c(5, 6), vars = \"year\") #> # A tibble: 20,393 × 3 #> # Groups:   ID, text [19,063] #>       ID text                                        year #>    <dbl> <chr>                                      <dbl> #>  1     5 FRANKENSTEIN                                1818 #>  2     5 OR                                          1818 #>  3     5 THE MODERN PROMETHEUS                       1818 #>  4     5 BY MARY W                                   1818 #>  5     5 SHELLEY                                     1818 #>  6     5 PREFACE                                     1818 #>  7     5 The event on which this fiction is founded  1818 #>  8     5 has been supposed                           1818 #>  9     5 by Dr                                       1818 #> 10     5 Darwin                                      1818 #> # ℹ 20,383 more rows"},{"path":"https://anshalmm.github.io/corpuscleaner/articles/corpuscleaner.html","id":"usage-in-text-analysis","dir":"Articles","previous_headings":"Understanding corpuscleaner","what":"Usage in Text Analysis","title":"Introduction of corpuscleaner","text":"Aside , can higher corpus analysis tf-idf: Topic Modeling: Therefore, package useful higher basic Corpus Analysis.","code":"# Using novels() to do tf-idf # Part 1: Finding the commonly used words in all documents doc_words = novels() %>%   unnest_tokens(word, text) %>%   count(title, word, sort = T)  tot_words = doc_words %>%   group_by(title) %>%    summarize(total = sum(n))  put_words = left_join(doc_words, tot_words) put_words #> # A tibble: 150,525 × 4 #>    title                    word      n  total #>    <chr>                    <chr> <int>  <int> #>  1 The Mysteries of Udolpho the   19063 294093 #>  2 The Woman in White       the   14947 250487 #>  3 Ivanhoe                  the   12464 179284 #>  4 The Mysteries of Udolpho and    9818 294093 #>  5 The Mysteries of Udolpho to     9693 294093 #>  6 The Mysteries of Udolpho of     9523 294093 #>  7 The Woman in White       to     8486 250487 #>  8 Great Expectations       the    8145 188943 #>  9 The Portrait of a Lady   the    8066 233165 #> 10 Dracula                  the    7865 161799 #> # ℹ 150,515 more rows  # Part 2: Using Zipf's law in Finding Word Frequency frequency_rank = put_words %>%                     group_by(title) %>%                     mutate(rank = row_number(),                            term_frequency = n/total) %>%                     ungroup()  frequency_rank #> # A tibble: 150,525 × 6 #>    title                    word      n  total  rank term_frequency #>    <chr>                    <chr> <int>  <int> <int>          <dbl> #>  1 The Mysteries of Udolpho the   19063 294093     1         0.0648 #>  2 The Woman in White       the   14947 250487     1         0.0597 #>  3 Ivanhoe                  the   12464 179284     1         0.0695 #>  4 The Mysteries of Udolpho and    9818 294093     2         0.0334 #>  5 The Mysteries of Udolpho to     9693 294093     3         0.0330 #>  6 The Mysteries of Udolpho of     9523 294093     4         0.0324 #>  7 The Woman in White       to     8486 250487     2         0.0339 #>  8 Great Expectations       the    8145 188943     1         0.0431 #>  9 The Portrait of a Lady   the    8066 233165     1         0.0346 #> 10 Dracula                  the    7865 161799     1         0.0486 #> # ℹ 150,515 more rows # Using novels to do some Topic Modeling # Part 1: Find the books you want to use in Topic Modeling  # Search for Novels that have CHAPTER I... In Them  novels() %>%   filter(str_detect(text, \"^CHAPTER \")) %>%   select(title, text) #> # A tibble: 293 × 2 #>    title             text         #>    <chr>             <chr>        #>  1 Wuthering Heights CHAPTER I    #>  2 Wuthering Heights CHAPTER II   #>  3 Wuthering Heights CHAPTER III  #>  4 Wuthering Heights CHAPTER IV   #>  5 Wuthering Heights CHAPTER V    #>  6 Wuthering Heights CHAPTER VI   #>  7 Wuthering Heights CHAPTER VII  #>  8 Wuthering Heights CHAPTER VIII #>  9 Wuthering Heights CHAPTER IX   #> 10 Wuthering Heights CHAPTER X    #> # ℹ 283 more rows  # Optional:  # novels() %>% #   filter(str_detect(text, \"^CHAPTER \")) %>% #   select(title, text) %>% #   print(n = 250)  book_titles = c(\"Frankenstein\", \"Ivanhoe\", \"The Portrait of a Lady\", \"Wuthering Heights\")  books = novels() %>%   filter(title %in% book_titles)  # Diving these books by chapter  book_chapters = books %>%   group_by(title) %>%   mutate(chapter = cumsum(str_detect(text, \"^CHAPTER \"))) %>%   filter(chapter > 0) %>%   unite(document, title, chapter)  book_words = book_chapters %>%   unnest_tokens(word, text)   book_wordcounts = book_words %>%   anti_join(get_stopwords(\"en\", source = \"smart\")) %>%   count(document, word, sort = T)  book_wordcounts #> # A tibble: 140,505 × 3 #>    document                  word       n #>    <chr>                     <chr>  <int> #>  1 Ivanhoe_27                thou      75 #>  2 The Portrait of a Lady_19 isabel    69 #>  3 Ivanhoe_40                knight    66 #>  4 Ivanhoe_27                de        61 #>  5 The Portrait of a Lady_40 isabel    61 #>  6 Ivanhoe_39                thou      60 #>  7 The Portrait of a Lady_51 isabel    57 #>  8 Ivanhoe_33                thou      55 #>  9 Ivanhoe_33                prior     53 #> 10 The Portrait of a Lady_52 isabel    53 #> # ℹ 140,495 more rows  # Part 2: Convert to LDA for Topic Modeling book_chapter_DTM = book_wordcounts %>%                             cast_dtm(document, word, n)  book_chapter_DTM #> <<DocumentTermMatrix (documents: 157, terms: 19685)>> #> Non-/sparse entries: 140505/2950040 #> Sparsity           : 95% #> Maximal term length: 18 #> Weighting          : term frequency (tf)  # Use LDA in Four Topic Modeling given we have Four Documents book_chapter_LDA = LDA(book_chapter_DTM, k = 4, control = list(seed = 1234)) book_chapter_LDA #> A LDA_VEM topic model with 4 topics.  # Finally, examine a per topic per word probabilities  book_topics = tidy(book_chapter_LDA, matrix = \"beta\") book_topics #> # A tibble: 78,740 × 3 #>    topic term        beta #>    <int> <chr>      <dbl> #>  1     1 thou   2.16e-  4 #>  2     2 thou   3.70e-  4 #>  3     3 thou   6.10e-172 #>  4     4 thou   1.26e-  2 #>  5     1 isabel 2.07e- 11 #>  6     2 isabel 5.23e- 21 #>  7     3 isabel 1.93e-  2 #>  8     4 isabel 9.50e-208 #>  9     1 knight 3.88e- 22 #> 10     2 knight 4.70e- 36 #> # ℹ 78,730 more rows"},{"path":"https://anshalmm.github.io/corpuscleaner/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Anshal Majmudar. Author, maintainer.","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Majmudar (2024). corpuscleaner: Tibble 18 Cleaned Documents usable Text Analysis. R package version 0.1.0, https://anshalmm.github.io/corpuscleaner/.","code":"@Manual{,   title = {corpuscleaner: A Tibble of 18 Cleaned Documents usable for Text Analysis},   author = {Anshal Majmudar},   year = {2024},   note = {R package version 0.1.0},   url = {https://anshalmm.github.io/corpuscleaner/}, }"},{"path":[]},{"path":"https://anshalmm.github.io/corpuscleaner/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"A Tibble of 18 Cleaned Documents usable for Text Analysis","text":"corpuscleaner package collection 18 Documents cleaned ready use regarding Corpus Analysis. novels() function collection consisting : title: Title Document text: Text Document year: Year Document Published author: Author Document novel_bookshelf: Category Document also function novels_by_ID(..., vars) consists : ID text can add column_name choice year, author, .","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"A Tibble of 18 Cleaned Documents usable for Text Analysis","text":"can install development version corpuscleaner GitHub :","code":"# install.packages(\"corpuscleaner\") devtools::install_github(\"anshalmm/corpuscleaner\")"},{"path":"https://anshalmm.github.io/corpuscleaner/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"A Tibble of 18 Cleaned Documents usable for Text Analysis","text":"basic examples corpuscleaner can show combined basic text analysis: ’re using novels() function filtering find metadata document Wuthering Heights can use novels_by_ID function extract ID, text, additional column, author, document Vathek. can frequency list text analysis document finding unigrams : like know package, please see Get started Page.","code":"library(corpuscleaner) library(dplyr) library(tidytext) WH_Text = novels() %>%   filter(title == \"Wuthering Heights\")  WH_Text #> # A tibble: 20,721 × 5 #>       ID title             text                                      year author #>    <dbl> <chr>             <chr>                                    <dbl> <chr>  #>  1     1 Wuthering Heights WUTHERING HEIGHTS                         1847 Bront… #>  2     1 Wuthering Heights CHAPTER I                                 1847 Bront… #>  3     1 Wuthering Heights I have just returned from a visit to my…  1847 Bront… #>  4     1 Wuthering Heights This is certainly a beautiful country     1847 Bront… #>  5     1 Wuthering Heights In all England                            1847 Bront… #>  6     1 Wuthering Heights I do not believe that I could have fixe…  1847 Bront… #>  7     1 Wuthering Heights A perfect misanthropist s heaven          1847 Bront… #>  8     1 Wuthering Heights and Mr                                    1847 Bront… #>  9     1 Wuthering Heights Heathcliff and I are such a suitable pa…  1847 Bront… #> 10     1 Wuthering Heights A capital fellow                          1847 Bront… #> # ℹ 20,711 more rows novels() #> # A tibble: 369,611 × 5 #>       ID title             text                                      year author #>    <dbl> <chr>             <chr>                                    <dbl> <chr>  #>  1     1 Wuthering Heights WUTHERING HEIGHTS                         1847 Bront… #>  2     1 Wuthering Heights CHAPTER I                                 1847 Bront… #>  3     1 Wuthering Heights I have just returned from a visit to my…  1847 Bront… #>  4     1 Wuthering Heights This is certainly a beautiful country     1847 Bront… #>  5     1 Wuthering Heights In all England                            1847 Bront… #>  6     1 Wuthering Heights I do not believe that I could have fixe…  1847 Bront… #>  7     1 Wuthering Heights A perfect misanthropist s heaven          1847 Bront… #>  8     1 Wuthering Heights and Mr                                    1847 Bront… #>  9     1 Wuthering Heights Heathcliff and I are such a suitable pa…  1847 Bront… #> 10     1 Wuthering Heights A capital fellow                          1847 Bront… #> # ℹ 369,601 more rows novels_by_ID(ID = 2, vars = \"year\") #> # A tibble: 5,259 × 3 #> # Groups:   ID, text [4,903] #>       ID text              year #>    <dbl> <chr>            <dbl> #>  1     2 VATHEK            1786 #>  2     2 AN ARABIAN TALE   1786 #>  3     2 BY                1786 #>  4     2 WILLIAM BECKFORD  1786 #>  5     2 ESQ               1786 #>  6     2 p                 1786 #>  7     2 VATHEK            1786 #>  8     2 Vathek            1786 #>  9     2 ninth Caliph      1786 #> 10     2 a                 1786 #> # ℹ 5,249 more rows unigram_Analysis = novels_by_ID(ID = 2, vars = \"year\")  UA = unigram_Analysis %>%   unnest_tokens(word,                  text,                  token = \"words\") %>%   anti_join(get_stopwords(\"en\", source = \"smart\"))   UA_Count_Words = UA %>%   count(word, sort = T) UA_Count_Words #> # A tibble: 5,393 × 3 #> # Groups:   ID [1] #>       ID word            n #>    <dbl> <chr>       <int> #>  1     2 caliph        151 #>  2     2 vathek        125 #>  3     2 nouronihar     87 #>  4     2 carathis       79 #>  5     2 thy            78 #>  6     2 thou           72 #>  7     2 whilst         66 #>  8     2 bababalouk     55 #>  9     2 gulchenrouz    54 #> 10     2 palace         47 #> # ℹ 5,383 more rows"},{"path":"https://anshalmm.github.io/corpuscleaner/reference/corpuscleaner-package.html","id":null,"dir":"Reference","previous_headings":"","what":"corpuscleaner: A Tibble of 18 Cleaned Documents usable for Text Analysis — corpuscleaner-package","title":"corpuscleaner: A Tibble of 18 Cleaned Documents usable for Text Analysis — corpuscleaner-package","text":"package two major functions novels() polish(..., vars). know please refer Vignette.","code":""},{"path":[]},{"path":"https://anshalmm.github.io/corpuscleaner/reference/corpuscleaner-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"corpuscleaner: A Tibble of 18 Cleaned Documents usable for Text Analysis — corpuscleaner-package","text":"Maintainer: Anshal Majmudar ammajmudar@ucdavis.edu","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels.html","id":null,"dir":"Reference","previous_headings":"","what":"18 Cleaned Novels — novels","title":"18 Cleaned Novels — novels","text":"complete cleaned tibble 18 Documents usable Corpus Analytics","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"18 Cleaned Novels — novels","text":"","code":"novels()"},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"18 Cleaned Novels — novels","text":"dataframe 369111 rows 6 variables consisting : ID ID Documents title Title Documents text Text Documents year Year Published author Author Documents","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"18 Cleaned Novels — novels","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union library(tidytext) novels() %>%   unnest_tokens(word, text) %>%   anti_join(get_stopwords(\"en\", source = \"smart\")) %>%   count(ID, title, word, sort = TRUE) #> Joining with `by = join_by(word)` #> # A tibble: 143,198 × 4 #>       ID title                    word         n #>    <dbl> <chr>                    <chr>    <int> #>  1     7 The Mysteries of Udolpho emily     2227 #>  2    16 The Portrait of a Lady   isabel    1485 #>  3    13 North and South          margaret  1443 #>  4    13 North and South          mr         989 #>  5    10 Ivanhoe                  thou       947 #>  6     7 The Mysteries of Udolpho montoni    918 #>  7    14 The Woman in White       sir        842 #>  8    16 The Portrait of a Lady   don        833 #>  9    14 The Woman in White       percival   749 #> 10    15 Great Expectations       joe        747 #> # ℹ 143,188 more rows"},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels_by_ID.html","id":null,"dir":"Reference","previous_headings":"","what":"Novels Extraction — novels_by_ID","title":"Novels Extraction — novels_by_ID","text":"function allows extract novel(s) choice based title choose along extra parameters like see year author.","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels_by_ID.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Novels Extraction — novels_by_ID","text":"","code":"novels_by_ID(ID, vars)"},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels_by_ID.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Novels Extraction — novels_by_ID","text":"ID Input ID (.e., 1:18) novels() function vars Input column variable novels() function","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels_by_ID.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Novels Extraction — novels_by_ID","text":"dataframe ID, text, column variable choice","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels_by_ID.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Novels Extraction — novels_by_ID","text":"","code":"novels_by_ID(ID = c(5, 6), vars = \"year\") #> # A tibble: 20,393 × 3 #> # Groups:   ID, text [19,063] #>       ID text                                        year #>    <dbl> <chr>                                      <dbl> #>  1     5 FRANKENSTEIN                                1818 #>  2     5 OR                                          1818 #>  3     5 THE MODERN PROMETHEUS                       1818 #>  4     5 BY MARY W                                   1818 #>  5     5 SHELLEY                                     1818 #>  6     5 PREFACE                                     1818 #>  7     5 The event on which this fiction is founded  1818 #>  8     5 has been supposed                           1818 #>  9     5 by Dr                                       1818 #> 10     5 Darwin                                      1818 #> # ℹ 20,383 more rows"},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels_tgt.html","id":null,"dir":"Reference","previous_headings":"","what":"18 Cleaned Documents — novels_tgt","title":"18 Cleaned Documents — novels_tgt","text":"Tibble 18 Cleaned Documents usable Corpus Analysis","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels_tgt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"18 Cleaned Documents — novels_tgt","text":"","code":"novels_tgt"},{"path":"https://anshalmm.github.io/corpuscleaner/reference/novels_tgt.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"18 Cleaned Documents — novels_tgt","text":"tibble 369111 rows 6 variables consisting : ID ID Novels title Title Novels text Text Novels year Year Published author Author Novels","code":""},{"path":"https://anshalmm.github.io/corpuscleaner/news/index.html","id":"corpuscleaner-010","dir":"Changelog","previous_headings":"","what":"corpuscleaner 0.1.0","title":"corpuscleaner 0.1.0","text":"Initial CRAN submission.","code":""}]
